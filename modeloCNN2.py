import tensorflow as tf
from tensorflow.keras.preprocessing.image import ImageDataGenerator
from tensorflow.keras.applications import EfficientNetB0
from tensorflow.keras.models import Sequential, load_model
from tensorflow.keras.layers import Dense, GlobalAveragePooling2D, Dropout
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint
import os
import matplotlib.pyplot as plt
import sys
import numpy as np
from sklearn.metrics import classification_report, confusion_matrix
import seaborn as sns # Importaci√≥n para visualizar la matriz

# --- 1. CONFIGURACI√ìN INICIAL Y PAR√ÅMETROS ---

# La ruta base donde se encuentran las carpetas 'QUENUAL' y 'NO QUENUAL'
BASE_DIR = r"C:\Nikol\Universidad\DatasetTesis"

# Par√°metros
IMG_SIZE = (224, 224) 
BATCH_SIZE = 32
RANDOM_SEED = 42
tf.random.set_seed(RANDOM_SEED)

# N√∫mero de canales (RGB)
INPUT_CHANNELS = 3 
VALIDATION_SPLIT = 0.30 # 30% para Validaci√≥n

# --- 2. PREPARACI√ìN DE DATOS (Data Augmentation Corregido) ---

print(f"--- 1. PREPARACI√ìN DE DATOS (Divisi√≥n {1-VALIDATION_SPLIT} Train / {VALIDATION_SPLIT} Val, Modo: RGB) ---")

# Generador de datos con AUMENTO AGRESIVO (Correcci√≥n de Overfitting)
train_datagen = ImageDataGenerator(
    rescale=1./255,
    rotation_range=30,     # Aumentado a 30
    width_shift_range=0.3, # Aumentado a 0.3
    height_shift_range=0.3,# Aumentado a 0.3
    shear_range=0.3,
    zoom_range=0.3,        # Aumentado a 0.3
    horizontal_flip=True,
    fill_mode='nearest',
    validation_split=VALIDATION_SPLIT 
)

# Generador de validaci√≥n (solo reescalado, sin augmentation)
val_datagen = ImageDataGenerator(rescale=1./255, validation_split=VALIDATION_SPLIT)


# Carga de datos de entrenamiento (70%)
train_generator = train_datagen.flow_from_directory(
    BASE_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    color_mode='rgb',
    subset='training',
    seed=RANDOM_SEED
)

# Carga de datos de validaci√≥n (30%)
validation_generator = val_datagen.flow_from_directory(
    BASE_DIR,
    target_size=IMG_SIZE,
    batch_size=BATCH_SIZE,
    class_mode='binary',
    color_mode='rgb',
    subset='validation',
    seed=RANDOM_SEED,
    shuffle=False # Crucial para la Matriz de Confusi√≥n
)

# Obtener los nombres de las clases para la matriz
CLASS_LABELS = list(validation_generator.class_indices.keys())


# --- 3. CONSTRUCCI√ìN DEL MODELO (Regularizaci√≥n y Entrenabilidad Corregida) ---

print("\n--- 2. ARQUITECTURA DEL MODELO (Entrenamiento desde Cero con Regularizaci√≥n) ---")

base_model = EfficientNetB0(
    weights=None, # Entrenar desde pesos aleatorios.
    include_top=False, 
    input_shape=(IMG_SIZE[0], IMG_SIZE[1], INPUT_CHANNELS)
)

print("\n‚ö†Ô∏è ADVERTENCIA: Entrenando desde CERO. Dropout y LR ajustados para combatir el sobreajuste.")

base_model.trainable = True 

model = Sequential([
    base_model,
    GlobalAveragePooling2D(), 
    Dense(256, activation='relu'), 
    Dropout(0.7), # <--- CORRECCI√ìN: Dropout aumentado a 0.7 para regularizaci√≥n
    Dense(1, activation='sigmoid') 
], name="Quenual_Classifier")

# Compilaci√≥n para la FASE 1 (Entrenamiento completo)
model.compile(
    optimizer=Adam(learning_rate=0.0005), # <--- CORRECCI√ìN: Tasa de Aprendizaje reducida a 0.0005
    loss='binary_crossentropy',
    metrics=['accuracy']
)

model.summary()

# Callbacks
MODEL_PATH = 'best_model_quenual2.keras'
callbacks = [
    EarlyStopping(monitor='val_loss', patience=15, mode='min', verbose=1), 
    ModelCheckpoint(filepath=MODEL_PATH, monitor='val_accuracy', save_best_only=True, mode='max')
]

# --- 4. ENTRENAMIENTO (Fase 1: Entrenamiento Completo) ---

print("\n--- 3. INICIANDO FASE 1: ENTRENAMIENTO COMPLETO (30 √âPOCAS) ---")
initial_epochs = 30 # Aumentamos las √©pocas a 30

history = model.fit(
    train_generator,
    epochs=initial_epochs,
    validation_data=validation_generator,
    callbacks=callbacks
)

# --- 5. AJUSTE FINO (Fase 2: Optimizaci√≥n del Aprendizaje) ---

print("\n--- 4. INICIANDO FASE 2: AJUSTE FINO (Optimizaci√≥n con LR bajo) ---")

try:
    model = load_model(MODEL_PATH)
except:
    print("No se pudo cargar el modelo guardado. Continuando con el modelo actual.")
    pass

# Re-compilaci√≥n con tasa de aprendizaje MUY baja para el ajuste fino
model.compile(
    optimizer=Adam(learning_rate=0.00001), 
    loss='binary_crossentropy',
    metrics=['accuracy']
)

fine_tune_epochs = 20 
total_epochs = initial_epochs + fine_tune_epochs

history_fine = model.fit(
    train_generator,
    epochs=total_epochs,
    initial_epoch=history.epoch[-1], 
    validation_data=validation_generator,
    callbacks=callbacks
)

# --- 6. EVALUACI√ìN Y AN√ÅLISIS DETALLADO (Falsos Positivos y Matriz) ---

print("\n--- 5. EVALUACI√ìN Y AN√ÅLISIS DETALLADO SOBRE CONJUNTO DE VALIDACI√ìN ---")

# Cargar el modelo final (el mejor)
try:
    final_model = load_model(MODEL_PATH)
except:
    final_model = model

# 1. Obtener Predicciones
validation_generator.reset()
predictions = final_model.predict(validation_generator, verbose=0)
predicted_classes = (predictions > 0.5).astype(int)
true_classes = validation_generator.classes 

# 2. Generar y Visualizar la Matriz de Confusi√≥n
cm = confusion_matrix(true_classes, predicted_classes)
print("\nMatriz de Confusi√≥n (Valores Brutos):\n", cm)

plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
            xticklabels=CLASS_LABELS, yticklabels=CLASS_LABELS)
plt.xlabel('Predicci√≥n')
plt.ylabel('Valor Verdadero')
plt.title('Matriz de Confusi√≥n')
plt.show() # Mostrar el gr√°fico de la matriz


# 3. Reporte de Clasificaci√≥n (Incluye m√©tricas como Precision, Recall y F1-Score)
report = classification_report(true_classes, predicted_classes, target_names=CLASS_LABELS)
print("\nReporte de Clasificaci√≥n Detallado:\n", report)

# Evaluaci√≥n de la precisi√≥n global y Falsos Positivos
val_loss, val_accuracy = final_model.evaluate(validation_generator, verbose=0)
fp_count = cm[0, 1] 

print("\n=======================================================")
print(f"| ‚úÖ Precisi√≥n Global (Accuracy): {val_accuracy*100:.2f}% |")
print(f"| üö® Falsos Positivos (FP): {fp_count} im√°genes         |")
print("=======================================================")

# --- 7. VISUALIZACI√ìN DE RESULTADOS ---

# Combinar historial de ambas fases
acc = history.history['accuracy'] + history_fine.history['accuracy']
val_acc = history.history['val_accuracy'] + history_fine.history['val_accuracy']
loss = history.history['loss'] + history_fine.history['loss']
val_loss_hist = history.history['val_loss'] + history_fine.history['val_loss']

plt.figure(figsize=(12, 4))
plt.subplot(1, 2, 1)
plt.plot(acc, label='Precisi√≥n de Entrenamiento')
plt.plot(val_acc, label='Precisi√≥n de Validaci√≥n')
plt.axhline(y=0.90, color='r', linestyle='--', label='Meta 90%')
plt.legend(loc='lower right')
plt.title('Precisi√≥n (Training vs Validation)')

plt.subplot(1, 2, 2)
plt.plot(loss, label='P√©rdida de Entrenamiento')
plt.plot(val_loss_hist, label='P√©rdida de Validaci√≥n')
plt.legend(loc='upper right')
plt.title('P√©rdida (Training vs Validation)')
plt.show()